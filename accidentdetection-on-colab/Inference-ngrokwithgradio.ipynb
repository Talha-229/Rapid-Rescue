{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHj8TERCO8jJ",
        "outputId": "6063adbe-9cb6-40cb-b443-b97dff3d9e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pyjwt in /usr/local/lib/python3.11/dist-packages (2.10.1)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python numpy onnxruntime requests pyjwt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCnB0hdXvOXp",
        "outputId": "43788585-5d32-4603-a0ce-32b5de4f3689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Downloading onnxruntime_gpu-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (283.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnxruntime-gpu\n",
            "Successfully installed onnxruntime-gpu-1.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WLvETfF-wGn",
        "outputId": "b449508a-db83-4f83-cb3d-a4fc8ccb62f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,801 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,748 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,562 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,351 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,254 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,741 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,040 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,058 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,587 kB]\n",
            "Fetched 32.5 MB in 5s (6,938 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i50UM3AGvLUM",
        "outputId": "5bc7d397-4e0d-4693-aea7-c82b82e78ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.13)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "import requests\n",
        "import json\n",
        "import random\n",
        "from datetime import datetime\n",
        "import string\n",
        "import os\n",
        "from collections import deque\n",
        "import time\n",
        "import threading\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import base64\n",
        "import secrets\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "import gc\n",
        "import psutil\n",
        "import re\n",
        "import mimetypes\n",
        "import gradio as gr\n",
        "import traceback\n",
        "\n",
        "# Check GPU availability and setup\n",
        "def check_gpu_setup():\n",
        "    \"\"\"Check and display GPU information\"\"\"\n",
        "    print(\"=== GPU Setup Check ===\")\n",
        "    cuda_available = 'CUDAExecutionProvider' in onnxruntime.get_available_providers()\n",
        "    print(f\"CUDA Available: {cuda_available}\")\n",
        "    available_providers = onnxruntime.get_available_providers()\n",
        "    print(f\"Available Providers: {available_providers}\")\n",
        "    try:\n",
        "        import GPUtil\n",
        "        gpus = GPUtil.getGPUs()\n",
        "        if gpus:\n",
        "            for gpu in gpus:\n",
        "                print(f\"GPU: {gpu.name}, Memory: {gpu.memoryUsed}MB/{gpu.memoryTotal}MB\")\n",
        "    except ImportError:\n",
        "        print(\"GPUtil not available - install with: !pip install GPUtil\")\n",
        "    memory_info = psutil.virtual_memory()\n",
        "    print(f\"System RAM: {memory_info.used//1024//1024}MB/{memory_info.total//1024//1024}MB\")\n",
        "    print(\"=\" * 30)\n",
        "    return cuda_available\n",
        "\n",
        "class GPUOptimizedFrameProcessor:\n",
        "    def __init__(self, model_path, enable_gpu=True):\n",
        "        self.cuda_available = 'CUDAExecutionProvider' in onnxruntime.get_available_providers()\n",
        "        print(f\"CUDA Available: {self.cuda_available}\")\n",
        "        providers = []\n",
        "        if enable_gpu and self.cuda_available:\n",
        "            cuda_provider_options = {\n",
        "                'device_id': 0,\n",
        "                'arena_extend_strategy': 'kNextPowerOfTwo',\n",
        "                'gpu_mem_limit': 4 * 1024 * 1024 * 1024,\n",
        "                'cudnn_conv_algo_search': 'EXHAUSTIVE',\n",
        "                'do_copy_in_default_stream': True,\n",
        "            }\n",
        "            providers.append(('CUDAExecutionProvider', cuda_provider_options))\n",
        "            print(\"✅ GPU acceleration enabled\")\n",
        "        providers.append('CPUExecutionProvider')\n",
        "        sess_options = onnxruntime.SessionOptions()\n",
        "        sess_options.enable_cpu_mem_arena = False\n",
        "        sess_options.enable_mem_pattern = False\n",
        "        sess_options.enable_mem_reuse = False\n",
        "        sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "        if enable_gpu and self.cuda_available:\n",
        "            sess_options.intra_op_num_threads = 1\n",
        "            sess_options.inter_op_num_threads = 1\n",
        "        else:\n",
        "            sess_options.intra_op_num_threads = 2\n",
        "            sess_options.inter_op_num_threads = 1\n",
        "        try:\n",
        "            self.session = onnxruntime.InferenceSession(model_path, sess_options, providers=providers)\n",
        "            self.input_name = self.session.get_inputs()[0].name\n",
        "            provider_used = self.session.get_providers()[0]\n",
        "            print(f\"Active Provider: {provider_used}\")\n",
        "            input_shape = self.session.get_inputs()[0].shape\n",
        "            self.input_height = input_shape[2] if len(input_shape) > 2 else 640\n",
        "            self.input_width = input_shape[3] if len(input_shape) > 3 else 640\n",
        "            self.local = threading.local()\n",
        "            print(f\"Model loaded successfully: {model_path}\")\n",
        "            print(f\"Input size: {self.input_width}x{self.input_height}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading model: {e}\")\n",
        "            raise\n",
        "\n",
        "    def get_canvas(self):\n",
        "        if not hasattr(self.local, 'canvas'):\n",
        "            self.local.canvas = np.full((self.input_height, self.input_width, 3), 114, dtype=np.uint8)\n",
        "        return self.local.canvas\n",
        "\n",
        "    def preprocess_image(self, img):\n",
        "        h, w = img.shape[:2]\n",
        "        scale = min(self.input_width/w, self.input_height/h)\n",
        "        new_w = int(w * scale)\n",
        "        new_h = int(h * scale)\n",
        "        resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
        "        canvas = self.get_canvas()\n",
        "        canvas.fill(114)\n",
        "        offset_x = (self.input_width - new_w) // 2\n",
        "        offset_y = (self.input_height - new_h) // 2\n",
        "        canvas[offset_y:offset_y+new_h, offset_x:offset_x+new_w] = resized\n",
        "        preprocessed = canvas.astype(np.float32) / 255.0\n",
        "        preprocessed = preprocessed.transpose(2, 0, 1)\n",
        "        preprocessed = np.expand_dims(preprocessed, axis=0)\n",
        "        preprocessed = np.ascontiguousarray(preprocessed)\n",
        "        return preprocessed, (scale, offset_x, offset_y)\n",
        "\n",
        "    def postprocess_detections(self, output, original_size, preprocess_params, conf_threshold=0.3):\n",
        "        try:\n",
        "            predictions = output[0].squeeze() if isinstance(output, list) else output.squeeze()\n",
        "            if len(predictions.shape) == 1:\n",
        "                return [], [], []\n",
        "            if predictions.shape[0] < predictions.shape[1]:\n",
        "                predictions = predictions.T\n",
        "            boxes = predictions[:, :4]\n",
        "            confidence_scores = predictions[:, 4]\n",
        "            conf_mask = confidence_scores >= conf_threshold\n",
        "            if not np.any(conf_mask):\n",
        "                return [], [], []\n",
        "            boxes = boxes[conf_mask]\n",
        "            scores = confidence_scores[conf_mask]\n",
        "            x_center, y_center, width, height = boxes.T\n",
        "            x1 = x_center - width / 2\n",
        "            y1 = y_center - height / 2\n",
        "            x2 = x_center + width / 2\n",
        "            y2 = y_center + height / 2\n",
        "            boxes = np.stack([x1, y1, x2, y2], axis=1)\n",
        "            scale, offset_x, offset_y = preprocess_params\n",
        "            boxes[:, [0, 2]] -= offset_x\n",
        "            boxes[:, [1, 3]] -= offset_y\n",
        "            boxes = boxes / scale\n",
        "            orig_h, orig_w = original_size\n",
        "            boxes[:, [0, 2]] = np.clip(boxes[:, [0, 2]], 0, orig_w)\n",
        "            boxes[:, [1, 3]] = np.clip(boxes[:, [1, 3]], 0, orig_h)\n",
        "            indices = cv2.dnn.NMSBoxes(\n",
        "                boxes.tolist(),\n",
        "                scores.tolist(),\n",
        "                conf_threshold,\n",
        "                0.4\n",
        "            )\n",
        "            if len(indices) > 0:\n",
        "                if isinstance(indices, np.ndarray):\n",
        "                    indices = indices.flatten()\n",
        "                final_boxes = boxes[indices].astype(np.int32)\n",
        "                final_scores = scores[indices]\n",
        "                class_ids = np.zeros(len(final_scores), dtype=int)\n",
        "                return final_boxes, final_scores, class_ids\n",
        "            return [], [], []\n",
        "        except Exception as e:\n",
        "            print(f\"Error in postprocessing: {e}\")\n",
        "            return [], [], []\n",
        "\n",
        "    def process_frame(self, frame, conf_threshold=0.3):\n",
        "        try:\n",
        "            preprocessed, preprocess_params = self.preprocess_image(frame)\n",
        "            outputs = self.session.run(None, {self.input_name: preprocessed})\n",
        "            boxes, scores, class_ids = self.postprocess_detections(\n",
        "                outputs, frame.shape[:2], preprocess_params, conf_threshold\n",
        "            )\n",
        "            return boxes, scores, class_ids\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing frame: {e}\")\n",
        "            return [], [], []\n",
        "\n",
        "class TemporalSmoothing:\n",
        "    def __init__(self, window_size=5):\n",
        "        self.window_size = window_size\n",
        "        self.score_history = deque(maxlen=window_size)\n",
        "\n",
        "    def update(self, scores):\n",
        "        if len(scores) == 0:\n",
        "            return scores\n",
        "        scores = np.array(scores, dtype=np.float32)\n",
        "        self.score_history.append(scores)\n",
        "        if len(self.score_history) > 1:\n",
        "            all_scores = list(self.score_history)\n",
        "            max_len = max(len(s) for s in all_scores)\n",
        "            padded_scores = []\n",
        "            for s in all_scores:\n",
        "                if len(s) < max_len:\n",
        "                    padded = np.zeros(max_len, dtype=np.float32)\n",
        "                    padded[:len(s)] = s\n",
        "                    padded_scores.append(padded)\n",
        "                else:\n",
        "                    padded_scores.append(s)\n",
        "            smoothed = np.mean(padded_scores, axis=0)\n",
        "            return smoothed[:len(scores)]\n",
        "        return scores\n",
        "\n",
        "def draw_detections(frame, boxes, scores, class_ids):\n",
        "    output = frame.copy()\n",
        "    for box, score, class_id in zip(boxes, scores, class_ids):\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        if score > 0.7:\n",
        "            color = (0, 255, 0)\n",
        "        elif score > 0.5:\n",
        "            color = (0, 255, 255)\n",
        "        else:\n",
        "            color = (0, 165, 255)\n",
        "        thickness = 2 if score > 0.6 else 1\n",
        "        cv2.rectangle(output, (x1, y1), (x2, y2), color, thickness)\n",
        "        label = f'ACCIDENT {score:.2f}'\n",
        "        (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "        cv2.rectangle(output, (x1, y1 - label_h - 8), (x1 + label_w + 4, y1), color, -1)\n",
        "        cv2.putText(output, label, (x1 + 2, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n",
        "    info_text = f'Detections: {len(boxes)}'\n",
        "    cv2.putText(output, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "    return output\n",
        "\n",
        "def save_accident_clip(frames, output_dir=\"/content/drive/MyDrive/accident_clips\"):\n",
        "    if len(frames) == 0:\n",
        "        return None\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    temp_path = os.path.join(output_dir, f\"temp_{timestamp}.mp4\")\n",
        "    video_path = os.path.join(output_dir, f\"accident_{timestamp}.mp4\")\n",
        "    try:\n",
        "        height, width = frames[0].shape[:2]\n",
        "        codecs = [\n",
        "            ('mp4v', cv2.VideoWriter_fourcc(*'mp4v')),\n",
        "            ('XVID', cv2.VideoWriter_fourcc(*'XVID'))\n",
        "        ]\n",
        "        video_writer = None\n",
        "        used_codec = None\n",
        "        for codec_name, codec in codecs:\n",
        "            video_writer = cv2.VideoWriter(\n",
        "                temp_path,\n",
        "                codec,\n",
        "                30.0,\n",
        "                (width, height),\n",
        "                True\n",
        "            )\n",
        "            if video_writer.isOpened():\n",
        "                video_writer.write(frames[0])\n",
        "                video_writer.release()\n",
        "                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 0:\n",
        "                    used_codec = (codec_name, codec)\n",
        "                    print(f\"Using {codec_name} codec\")\n",
        "                    break\n",
        "                else:\n",
        "                    print(f\"Codec {codec_name} failed to create valid file\")\n",
        "            else:\n",
        "                print(f\"Could not initialize {codec_name} codec\")\n",
        "            if video_writer:\n",
        "                video_writer.release()\n",
        "        if not used_codec:\n",
        "            print(\"Error: Could not find a working codec\")\n",
        "            return None\n",
        "        video_writer = cv2.VideoWriter(\n",
        "            temp_path,\n",
        "            used_codec[1],\n",
        "            30.0,\n",
        "            (width, height),\n",
        "            True\n",
        "        )\n",
        "        for frame in frames:\n",
        "            video_writer.write(frame)\n",
        "        video_writer.release()\n",
        "        cmd = f\"ffmpeg -i {temp_path} -vcodec h264 -acodec aac -movflags +faststart {video_path} -y\"\n",
        "        result = os.system(cmd)\n",
        "        if os.path.exists(temp_path):\n",
        "            os.remove(temp_path)\n",
        "        if os.path.exists(video_path) and os.path.getsize(video_path) > 0:\n",
        "            print(f\"Saved accident clip: {video_path}\")\n",
        "            print(f\"Video file size: {os.path.getsize(video_path)/1024/1024:.1f}MB\")\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            if cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                cap.release()\n",
        "                if ret:\n",
        "                    print(\"✅ Video file verification successful\")\n",
        "                else:\n",
        "                    print(\"⚠️ Warning: Could not read back video file\")\n",
        "            else:\n",
        "                print(\"⚠️ Warning: Could not open video file for verification\")\n",
        "            return video_path\n",
        "        else:\n",
        "            print(\"Error: Video file was not created properly\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving video clip: {e}\")\n",
        "        print(traceback.format_exc())\n",
        "        return None\n",
        "\n",
        "def cleanup_memory():\n",
        "    gc.collect()\n",
        "\n",
        "class AlertSender:\n",
        "    def __init__(self, api_url=\"https://b32a-14-1-106-250.ngrok-free.app\"):\n",
        "        if 'ngrok-free.app' in api_url:\n",
        "            api_url = re.sub(r':\\d+', '', api_url)\n",
        "            api_url = api_url.replace('http://', 'https://')\n",
        "        self.api_url = api_url\n",
        "        self.max_video_size = 10 * 1024 * 1024\n",
        "        self.jwt_token = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNzUyMDY5MDU3LCJpYXQiOjE3NDk0NzcwNTcsImp0aSI6IjlhNjZmNDFlZjU2ZTQ4OTFiYmUzNGRhMTc2MmQ2NWZiIiwidXNlcl9pZCI6MjMsImlzX3N0YWZmIjp0cnVlLCJpc19zdXBlcnVzZXIiOnRydWUsInVzZXJuYW1lIjoiYWRtaW4ifQ.lK0FCBT6It5aL1HUWsEQoDlYTlwTtINNj5Pt9T3uQyw\"\n",
        "        print(f\"AlertSender initialized with API URL: {self.api_url}\")\n",
        "\n",
        "    def test_connectivity(self):\n",
        "        try:\n",
        "            print(f\"Testing API connectivity at: {self.api_url}/api/alerts/\")\n",
        "            response = requests.get(\n",
        "                f\"{self.api_url}/api/alerts/\",\n",
        "                headers={\"Authorization\": f\"Bearer {self.jwt_token}\"},\n",
        "                verify=False,\n",
        "                timeout=5\n",
        "            )\n",
        "            print(f\"API test response status: {response.status_code}\")\n",
        "            return response.status_code == 200\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"⚠️ API test failed: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def save_alert_locally(self, confidence_score, video_path, frame_timestamp=None):\n",
        "        local_dir = \"/content/drive/MyDrive/accident_alerts\"\n",
        "        os.makedirs(local_dir, exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        alert_file = os.path.join(local_dir, f\"alert_{timestamp}.json\")\n",
        "        alert_data = {\n",
        "            'confidence_score': float(confidence_score),\n",
        "            'video_path': video_path,\n",
        "            'timestamp': frame_timestamp or datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'location': 'Gulberg III, Lahore',\n",
        "            'coordinates': {'lat': 31.5497, 'lng': 74.3436}\n",
        "        }\n",
        "        with open(alert_file, 'w') as f:\n",
        "            json.dump(alert_data, f, indent=2)\n",
        "        print(f\"Saved alert locally: {alert_file}\")\n",
        "\n",
        "    def send_accident_alert(self, confidence_score, video_path=None, frame_timestamp=None):\n",
        "        try:\n",
        "            if not self.test_connectivity():\n",
        "                print(\"Error: Cannot connect to API. Saving alert locally.\")\n",
        "                self.save_alert_locally(confidence_score, video_path, frame_timestamp)\n",
        "                return False\n",
        "            current_time = datetime.now()\n",
        "            alert_id = current_time.strftime('%m%d%H%M%S')\n",
        "            alert_data = {\n",
        "                'alert_id': alert_id,\n",
        "                'confidence_score': float(confidence_score),\n",
        "                'status': 'pending',\n",
        "                'location': 'Gulberg III, Lahore',\n",
        "                'date': current_time.strftime('%Y-%m-%d'),\n",
        "                'time': current_time.strftime('%H:%M:%S'),\n",
        "                'coordinates_lat': 31.5497,\n",
        "                'coordinates_lng': 74.3436,\n",
        "                'latitude': 31.5497,\n",
        "                'longitude': 74.3436,\n",
        "                'is_ai_detected': True\n",
        "            }\n",
        "            print(f\"Sending alert with ID: {alert_id}\")\n",
        "            print(f\"Alert data: {alert_data}\")\n",
        "            if video_path and os.path.exists(video_path):\n",
        "                print(f\"Processing video file: {video_path}\")\n",
        "                video_size = os.path.getsize(video_path)\n",
        "                print(f\"Video file size: {video_size/1024/1024:.1f}MB\")\n",
        "                if video_size <= self.max_video_size:\n",
        "                    try:\n",
        "                        cap = cv2.VideoCapture(video_path)\n",
        "                        if not cap.isOpened():\n",
        "                            print(\"⚠️ Warning: Could not open video file for verification\")\n",
        "                            return False\n",
        "                        ret, frame = cap.read()\n",
        "                        cap.release()\n",
        "                        if not ret:\n",
        "                            print(\"⚠️ Warning: Could not read video file\")\n",
        "                            return False\n",
        "                        print(\"✅ Video file verified before sending\")\n",
        "                        with open(video_path, 'rb') as video_file:\n",
        "                            video_filename = os.path.basename(video_path)\n",
        "                            files = {\n",
        "                                'accident_clip': (\n",
        "                                    video_filename,\n",
        "                                    video_file,\n",
        "                                    'video/mp4'\n",
        "                                )\n",
        "                            }\n",
        "                            print(f\"Sending request to: {self.api_url}/api/alerts/\")\n",
        "                            print(\"Request headers:\", {\n",
        "                                \"Authorization\": f\"Bearer {self.jwt_token}\",\n",
        "                                \"Accept\": \"application/json\",\n",
        "                                \"X-Requested-With\": \"XMLHttpRequest\"\n",
        "                            })\n",
        "                            response = requests.post(\n",
        "                                f\"{self.api_url}/api/alerts/\",\n",
        "                                data=alert_data,\n",
        "                                files=files,\n",
        "                                headers={\n",
        "                                    \"Authorization\": f\"Bearer {self.jwt_token}\",\n",
        "                                    \"Accept\": \"application/json\",\n",
        "                                    \"X-Requested-With\": \"XMLHttpRequest\"\n",
        "                                },\n",
        "                                timeout=30,\n",
        "                                verify=False\n",
        "                            )\n",
        "                            print(f\"\\nResponse status code: {response.status_code}\")\n",
        "                            try:\n",
        "                                response_json = response.json()\n",
        "                                print(f\"Response JSON: {response_json}\")\n",
        "                                if 'video_url' in response_json:\n",
        "                                    response_json['video_url'] = response_json['video_url'].replace('http://', 'https://')\n",
        "                                    print(f\"Video should be accessible at: {response_json['video_url']}\")\n",
        "                                if 'accident_clip_url' in response_json:\n",
        "                                    response_json['accident_clip_url'] = response_json['accident_clip_url'].replace('http://', 'https://')\n",
        "                                    print(f\"Accident clip should be accessible at: {response_json['accident_clip_url']}\")\n",
        "                            except Exception as e:\n",
        "                                print(f\"Warning: Could not parse response JSON: {str(e)}\")\n",
        "                                print(f\"Raw response content: {response.text}\")\n",
        "                            if response.status_code in [200, 201]:\n",
        "                                print(\"✅ Alert sent successfully!\")\n",
        "                                return True\n",
        "                            else:\n",
        "                                print(\"Error response:\", response.text)\n",
        "                                self.save_alert_locally(confidence_score, video_path, frame_timestamp)\n",
        "                                return False\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error uploading video: {str(e)}\")\n",
        "                        print(traceback.format_exc())\n",
        "                        self.save_alert_locally(confidence_score, video_path, frame_timestamp)\n",
        "                        return False\n",
        "                else:\n",
        "                    print(f\"Video file too large ({video_size/1024/1024:.1f}MB). Maximum size is {self.max_video_size/1024/1024}MB\")\n",
        "                    return False\n",
        "            else:\n",
        "                print(f\"Video path not found or invalid: {video_path}\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"Error sending alert: {str(e)}\")\n",
        "            print(traceback.format_exc())\n",
        "            self.save_alert_locally(confidence_score, video_path, frame_timestamp)\n",
        "            return False\n",
        "\n",
        "    def reset(self):\n",
        "        print(\"Resetting alert sender - ready to send new alerts\")\n",
        "\n",
        "def process_video(video_path):\n",
        "    \"\"\"Modified main function to process uploaded video and return results\"\"\"\n",
        "    gpu_available = check_gpu_setup()\n",
        "    MODEL_PATH = '/content/best.onnx'\n",
        "    CONFIDENCE_THRESHOLD = 0.3\n",
        "    ALERT_THRESHOLD = 0.3\n",
        "    USE_GPU = gpu_available\n",
        "    COOLDOWN_PERIOD = 300\n",
        "\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        return f\"Error: Model file '{MODEL_PATH}' not found!\\nPlease ensure the ONNX model file is in the correct location.\"\n",
        "\n",
        "    try:\n",
        "        processor = GPUOptimizedFrameProcessor(MODEL_PATH, enable_gpu=USE_GPU)\n",
        "        alert_sender = AlertSender(api_url=\"https://b32a-14-1-106-250.ngrok-free.app\")\n",
        "        temporal_smoother = TemporalSmoothing()\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            return f\"Error: Could not open video source '{video_path}'\"\n",
        "\n",
        "        # Get video FPS to calculate proper frame counts\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        if fps == 0:\n",
        "            fps = 30  # Default fallback\n",
        "\n",
        "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "        cap.set(cv2.CAP_PROP_FPS, fps)\n",
        "\n",
        "        output_text = []\n",
        "        output_text.append(\"🚀 Starting GPU-accelerated accident detection...\")\n",
        "        output_text.append(f\"Video FPS: {fps}\")\n",
        "        output_text.append(f\"Alert cooldown period: {COOLDOWN_PERIOD/60:.1f} minutes\")\n",
        "\n",
        "        frame_count = 0\n",
        "        processing_times = deque(maxlen=30)\n",
        "\n",
        "        # Buffer for 2 seconds before accident (pre-accident frames)\n",
        "        frames_per_2_seconds = int(fps * 2)\n",
        "        pre_accident_buffer = deque(maxlen=frames_per_2_seconds)\n",
        "\n",
        "        # Variables for post-accident collection\n",
        "        post_accident_frames = []\n",
        "        preserved_pre_accident_frames = []  # Store pre-accident frames at detection moment\n",
        "        total_accidents_detected = 0\n",
        "        collecting_post_accident = False\n",
        "        post_accident_count = 0\n",
        "        accident_confidence = 0.0\n",
        "        accident_detection_frame = None\n",
        "        last_alert_time = 0\n",
        "        alerts_sent_count = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        output_text.append(f\"Pre-accident buffer size: {frames_per_2_seconds} frames (2 seconds)\")\n",
        "        output_text.append(f\"Post-accident collection: {frames_per_2_seconds} frames (2 seconds)\")\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                output_text.append(\"\\n✅ Video processing completed!\")\n",
        "                output_text.append(f\"Total frames processed: {frame_count}\")\n",
        "                output_text.append(f\"Total accidents detected: {total_accidents_detected}\")\n",
        "                output_text.append(f\"Total alerts sent: {alerts_sent_count}\")\n",
        "                output_text.append(f\"Total processing time: {time.time() - start_time:.2f} seconds\")\n",
        "                break\n",
        "\n",
        "            frame_start_time = time.time()\n",
        "            current_time = time.time()\n",
        "\n",
        "            # Only add to pre-accident buffer if NOT collecting post-accident\n",
        "            # This prevents overwriting the preserved pre-accident frames\n",
        "            if not collecting_post_accident:\n",
        "                pre_accident_buffer.append(frame.copy())\n",
        "\n",
        "            # Process frame for accident detection\n",
        "            boxes, scores, class_ids = processor.process_frame(frame, CONFIDENCE_THRESHOLD)\n",
        "\n",
        "            if len(scores) > 0:\n",
        "                scores = temporal_smoother.update(scores)\n",
        "\n",
        "            max_confidence = np.max(scores) if len(scores) > 0 else 0.0\n",
        "\n",
        "            # Handle post-accident frame collection\n",
        "            if collecting_post_accident:\n",
        "                post_accident_frames.append(frame.copy())\n",
        "                post_accident_count += 1\n",
        "\n",
        "                # Check if we've collected enough post-accident frames (2 seconds)\n",
        "                if post_accident_count >= frames_per_2_seconds:\n",
        "                    output_text.append(f\"\\n📹 Creating accident clip...\")\n",
        "                    output_text.append(f\"Preserved pre-accident frames: {len(preserved_pre_accident_frames)}\")\n",
        "                    output_text.append(f\"Post-accident frames collected: {len(post_accident_frames)}\")\n",
        "\n",
        "                    # Create the complete 4-second clip\n",
        "                    # Use preserved pre-accident frames + collected post-accident frames\n",
        "                    complete_clip = preserved_pre_accident_frames + post_accident_frames[:frames_per_2_seconds]\n",
        "\n",
        "                    expected_total_frames = frames_per_2_seconds * 2  # 4 seconds total\n",
        "                    actual_frames = len(complete_clip)\n",
        "\n",
        "                    output_text.append(f\"Expected clip length: {expected_total_frames} frames (4 seconds)\")\n",
        "                    output_text.append(f\"Actual clip length: {actual_frames} frames\")\n",
        "                    output_text.append(f\"Pre-accident portion: {len(preserved_pre_accident_frames)} frames\")\n",
        "                    output_text.append(f\"Post-accident portion: {len(post_accident_frames[:frames_per_2_seconds])} frames\")\n",
        "\n",
        "                    if actual_frames >= expected_total_frames * 0.9:  # Allow 10% tolerance\n",
        "                        video_path = save_accident_clip(complete_clip)\n",
        "                        if video_path:\n",
        "                            if alert_sender.send_accident_alert(accident_confidence, video_path):\n",
        "                                alerts_sent_count += 1\n",
        "                                output_text.append(f\"\\n🚨 Alert #{alerts_sent_count} sent successfully!\")\n",
        "                                output_text.append(f\"📹 Clip contains: 2sec BEFORE + 2sec AFTER accident\")\n",
        "                                output_text.append(f\"🎯 Accident detected at frame {accident_detection_frame}\")\n",
        "                                output_text.append(f\"⏰ Next alert available in {COOLDOWN_PERIOD/60:.1f} minutes\")\n",
        "                            else:\n",
        "                                output_text.append(f\"\\n❌ Failed to send alert #{alerts_sent_count + 1}\")\n",
        "                        else:\n",
        "                            output_text.append(f\"\\n❌ Failed to save accident clip\")\n",
        "                    else:\n",
        "                        output_text.append(f\"\\n⚠️ Warning: Clip too short ({actual_frames} frames), skipping alert\")\n",
        "\n",
        "                    # Reset collection state\n",
        "                    collecting_post_accident = False\n",
        "                    post_accident_frames = []\n",
        "                    preserved_pre_accident_frames = []\n",
        "                    post_accident_count = 0\n",
        "                    accident_confidence = 0.0\n",
        "                    accident_detection_frame = None\n",
        "\n",
        "            # Check for new accident detection\n",
        "            elif max_confidence >= ALERT_THRESHOLD:\n",
        "                total_accidents_detected += 1\n",
        "                time_since_last_alert = current_time - last_alert_time\n",
        "                can_send_alert = (last_alert_time == 0) or (time_since_last_alert >= COOLDOWN_PERIOD)\n",
        "\n",
        "                if can_send_alert:\n",
        "                    # PRESERVE the current pre-accident buffer at the moment of detection\n",
        "                    preserved_pre_accident_frames = list(pre_accident_buffer)\n",
        "\n",
        "                    # Start collecting post-accident frames\n",
        "                    collecting_post_accident = True\n",
        "                    post_accident_frames = []  # Reset post-accident collection\n",
        "                    post_accident_count = 0\n",
        "                    accident_confidence = max_confidence\n",
        "                    accident_detection_frame = frame_count\n",
        "                    last_alert_time = current_time\n",
        "\n",
        "                    output_text.append(f\"\\n🚨 ACCIDENT DETECTED! Frame: {frame_count}\")\n",
        "                    output_text.append(f\"🎯 Confidence: {max_confidence:.3f}\")\n",
        "                    output_text.append(f\"📹 Pre-accident frames preserved: {len(preserved_pre_accident_frames)} frames\")\n",
        "                    output_text.append(f\"🔄 Now collecting {frames_per_2_seconds} post-accident frames...\")\n",
        "                    output_text.append(f\"⚠️ Pre-accident buffer frozen during collection\")\n",
        "                else:\n",
        "                    remaining_cooldown = COOLDOWN_PERIOD - time_since_last_alert\n",
        "                    if frame_count % 100 == 0:\n",
        "                        output_text.append(f\"\\n⏰ Alert cooldown active. Next alert in {remaining_cooldown/60:.1f} minutes\")\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "            # Progress updates\n",
        "            if frame_count % 100 == 0:\n",
        "                status = f\"Collecting post-accident ({post_accident_count}/{frames_per_2_seconds})\" if collecting_post_accident else \"Monitoring\"\n",
        "                output_text.append(f\"\\r[{status}] Frames: {frame_count}, Accidents: {total_accidents_detected}, Alerts: {alerts_sent_count}\")\n",
        "                cleanup_memory()\n",
        "\n",
        "        cleanup_memory()\n",
        "        cap.release()\n",
        "\n",
        "        output_text.append(\"\\n🧹 Cleanup completed\")\n",
        "        output_text.append(\"\\n📊 Final Statistics:\")\n",
        "        output_text.append(f\"Video FPS: {fps}\")\n",
        "        output_text.append(f\"Frames per 2 seconds: {frames_per_2_seconds}\")\n",
        "        output_text.append(f\"Total frames processed: {frame_count}\")\n",
        "        output_text.append(f\"Total accidents detected: {total_accidents_detected}\")\n",
        "        output_text.append(f\"Total alerts sent: {alerts_sent_count}\")\n",
        "\n",
        "        if frame_count > 0:\n",
        "            output_text.append(f\"Accident detection rate: {(total_accidents_detected/frame_count)*100:.2f}%\")\n",
        "\n",
        "        return \"\\n\".join(output_text)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"\\n❌ Error during processing: {e}\\n{traceback.format_exc()}\"\n",
        "\n",
        "def setup_colab_gpu():\n",
        "    print(\"Setting up GPU environment for Google Colab...\")\n",
        "    try:\n",
        "        import GPUtil\n",
        "    except ImportError:\n",
        "        print(\"Installing GPUtil for GPU monitoring...\")\n",
        "        os.system(\"pip install gputil\")\n",
        "    try:\n",
        "        import google.colab\n",
        "        print(\"✅ Running in Google Colab\")\n",
        "        gpu_info = os.popen('nvidia-smi').read()\n",
        "        if 'Tesla' in gpu_info or 'T4' in gpu_info or 'V100' in gpu_info:\n",
        "            print(\"✅ GPU detected and available\")\n",
        "        else:\n",
        "            print(\"⚠️ No GPU detected. Make sure to enable GPU in Runtime > Change runtime type\")\n",
        "    except ImportError:\n",
        "        print(\"⚠️ Not running in Google Colab\")\n",
        "    return check_gpu_setup()\n",
        "\n",
        "def gradio_process(video):\n",
        "    if video is None:\n",
        "        return \"Error: No video uploaded. Please upload a video file.\"\n",
        "    try:\n",
        "        temp_video_path = video\n",
        "        if not os.path.exists(temp_video_path):\n",
        "            return f\"Error: Video file not found at {temp_video_path}\"\n",
        "        result = process_video(temp_video_path)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"Error processing video: {str(e)}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Install required packages for Colab\n",
        "    import subprocess\n",
        "    import sys\n",
        "\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\", \"numpy\", \"onnxruntime\", \"requests\", \"pyjwt\", \"gradio\"])\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnxruntime-gpu\"])\n",
        "        subprocess.check_call([\"apt-get\", \"update\"])\n",
        "        subprocess.check_call([\"apt-get\", \"install\", \"-y\", \"ffmpeg\"])\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Warning: Package installation failed: {e}\")\n",
        "\n",
        "    setup_colab_gpu()\n",
        "    iface = gr.Interface(\n",
        "        fn=gradio_process,\n",
        "        inputs=[gr.Video(label=\"Upload Video Clip\")],\n",
        "        outputs=gr.Textbox(label=\"Processing Results\"),\n",
        "        title=\"Accident Detection System\",\n",
        "        description=\"Upload a video clip to detect accidents using GPU-accelerated processing.\"\n",
        "    )\n",
        "    iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "i31xDT2TSuSp",
        "outputId": "3ada4db2-e127-43f8-c4b5-7044edac4fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up GPU environment for Google Colab...\n",
            "✅ Running in Google Colab\n",
            "✅ GPU detected and available\n",
            "=== GPU Setup Check ===\n",
            "CUDA Available: True\n",
            "Available Providers: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
            "GPU: Tesla T4, Memory: 0.0MB/15360.0MB\n",
            "System RAM: 1288MB/12977MB\n",
            "==============================\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cf2d91325c96966588.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cf2d91325c96966588.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}